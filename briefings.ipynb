{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community import embeddings\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts  import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_local = ChatOllama(model='phi4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"./data/20250201/parsed_briefings_20250201.json\"\n",
    "\n",
    "with open(file1, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for briefing in data:\n",
    "    page_content = {\n",
    "        \"type\": briefing[\"type\"],\n",
    "        \"title\": briefing[\"title\"],\n",
    "        \"content\": briefing[\"content\"],\n",
    "        \"date\": briefing[\"date\"]\n",
    "        }\n",
    "    \n",
    "    metadata = {\n",
    "        \"url\": briefing[\"url\"]\n",
    "        }\n",
    "    \n",
    "    newDocument = {\n",
    "        \"page_content\": json.dumps(page_content, ensure_ascii=False),\n",
    "        \"metadata\": metadata\n",
    "        }\n",
    "    documents.append(newDocument)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'url': 'https://theminjoo.kr/main/sub/news//view.php?sno=0&brd=11&post=1209147&search='},\n",
      " 'page_content': '{\"type\": \"서면브리핑\", \"title\": \"[윤종군 원내대변인] AI 과학기술 발전의 조건이 윤석열 '\n",
      "                 '탄핵·내란 특검법 중지라니 국민의힘은 제 정신입니까?\", \"content\": \"윤종군 원내대변인 '\n",
      "                 '서면브리핑\\\\n■ AI 과학기술 발전의 조건이 윤석열 탄핵·내란 특검법 중지라니 국민의힘은 제 '\n",
      "                 '정신입니까?\\\\n딥시크의 등장으로 전 세계가 충격에 휩싸였습니다. 딥시크는 전 세계적인 인공지능 경쟁에 '\n",
      "                 '새로운 장을 열었습니다.\\\\n이에 더불어민주당 이재명 대표는 초당적인 협력과 함께 추경에 대대적인 인공지능 '\n",
      "                 '개발 지원 예산을 담아주길 요청했습니다.\\\\n그러나 국민의힘은 추경안을 요청하기 전에 먼저 내란 특검법과 '\n",
      "                 '내란 탄핵을 멈추라며 ‘내란 세력 수호’만 외치고 있습니다.\\\\n전 세계적인 AI 경쟁이 불타오르는데 이를 '\n",
      "                 '추경에 담아 경제 성장의 동력을 찾을 생각은 하지 않고 정치공세에만 몰두하고 있습니다. 국민의힘은 국가의 '\n",
      "                 '과학기술 발전과 미래 먹거리를 키워내는 일보다 정쟁과 정파가 먼저입니까?\\\\n‘반도체지원특별법’을 핑계 삼는 '\n",
      "                 '것도 파렴치합니다. 국민의힘의 파행으로 국회 산자위가 열리지 못하고 제대로 논의도 못하고 있습니다. '\n",
      "                 '국민의힘이 경제와 민생에 진심이라면 산자위 파행부터 해결하십시오.\\\\n우리가 내란과 정쟁으로 멈춰있는 동안 '\n",
      "                 '세계는 달리고 있습니다. 정부는 빨리 추경안을 편성해 제출하십시오. 더불어민주당은 반도체, AI 등 미래산업 '\n",
      "                 '육성을 위한 신속한 지원을 적극 검토할 것입니다.\\\\n국민의힘도 진정 대한민국의 미래를 걱정한다면 정치공세를 '\n",
      "                 '멈추고 추경 편성에 협조하십시오.\\\\n2025년 2월 1일\\\\n더불어민주당 공보국\", \"date\": '\n",
      "                 '\"2025-02-01\"}'}\n"
     ]
    }
   ],
   "source": [
    "pprint(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name = \"test2\"\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1024,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yh/12scbgj57_d8xq3nw0klxfq00000gn/T/ipykernel_7838/3115346873.py:2: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  vector_store = PineconeVectorStore(index=index, embedding=embeddings.OllamaEmbeddings(model=\"bge-m3\"))\n"
     ]
    }
   ],
   "source": [
    "index = pc.Index(index_name)\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings.OllamaEmbeddings(model=\"bge-m3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "vectorDocuments = []\n",
    "for document in documents:\n",
    "    vectorDocument = Document(page_content=document[\"page_content\"], metadata=document[\"metadata\"])\n",
    "    vectorDocuments.append(vectorDocument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['264',\n",
       " '265',\n",
       " '266',\n",
       " '267',\n",
       " '268',\n",
       " '269',\n",
       " '270',\n",
       " '271',\n",
       " '272',\n",
       " '273',\n",
       " '274',\n",
       " '275',\n",
       " '276',\n",
       " '277',\n",
       " '278',\n",
       " '279',\n",
       " '280',\n",
       " '281',\n",
       " '282',\n",
       " '283',\n",
       " '284',\n",
       " '285',\n",
       " '286',\n",
       " '287',\n",
       " '288',\n",
       " '289',\n",
       " '290',\n",
       " '291',\n",
       " '292',\n",
       " '293',\n",
       " '294',\n",
       " '295',\n",
       " '296',\n",
       " '297',\n",
       " '298',\n",
       " '299',\n",
       " '300',\n",
       " '301',\n",
       " '302',\n",
       " '303',\n",
       " '304',\n",
       " '305',\n",
       " '306',\n",
       " '307',\n",
       " '308',\n",
       " '309',\n",
       " '310',\n",
       " '311',\n",
       " '312',\n",
       " '313',\n",
       " '314',\n",
       " '315',\n",
       " '316',\n",
       " '317',\n",
       " '318',\n",
       " '319',\n",
       " '320',\n",
       " '321',\n",
       " '322',\n",
       " '323',\n",
       " '324',\n",
       " '325',\n",
       " '326',\n",
       " '327',\n",
       " '328',\n",
       " '329',\n",
       " '330',\n",
       " '331',\n",
       " '332',\n",
       " '333',\n",
       " '334',\n",
       " '335',\n",
       " '336',\n",
       " '337',\n",
       " '338',\n",
       " '339',\n",
       " '340',\n",
       " '341',\n",
       " '342',\n",
       " '343',\n",
       " '344',\n",
       " '345',\n",
       " '346',\n",
       " '347',\n",
       " '348',\n",
       " '349',\n",
       " '350',\n",
       " '351',\n",
       " '352',\n",
       " '353',\n",
       " '354',\n",
       " '355',\n",
       " '356',\n",
       " '357',\n",
       " '358',\n",
       " '359',\n",
       " '360',\n",
       " '361',\n",
       " '362',\n",
       " '363',\n",
       " '364',\n",
       " '365',\n",
       " '366',\n",
       " '367',\n",
       " '368',\n",
       " '369',\n",
       " '370',\n",
       " '371',\n",
       " '372',\n",
       " '373',\n",
       " '374',\n",
       " '375',\n",
       " '376',\n",
       " '377',\n",
       " '378',\n",
       " '379',\n",
       " '380',\n",
       " '381',\n",
       " '382',\n",
       " '383',\n",
       " '384',\n",
       " '385',\n",
       " '386',\n",
       " '387',\n",
       " '388',\n",
       " '389',\n",
       " '390',\n",
       " '391',\n",
       " '392',\n",
       " '393',\n",
       " '394',\n",
       " '395',\n",
       " '396',\n",
       " '397',\n",
       " '398',\n",
       " '399',\n",
       " '400',\n",
       " '401',\n",
       " '402',\n",
       " '403',\n",
       " '404',\n",
       " '405',\n",
       " '406',\n",
       " '407',\n",
       " '408',\n",
       " '409',\n",
       " '410',\n",
       " '411',\n",
       " '412',\n",
       " '413',\n",
       " '414',\n",
       " '415',\n",
       " '416',\n",
       " '417',\n",
       " '418',\n",
       " '419',\n",
       " '420',\n",
       " '421',\n",
       " '422',\n",
       " '423',\n",
       " '424',\n",
       " '425',\n",
       " '426',\n",
       " '427',\n",
       " '428',\n",
       " '429',\n",
       " '430',\n",
       " '431',\n",
       " '432',\n",
       " '433',\n",
       " '434',\n",
       " '435',\n",
       " '436',\n",
       " '437',\n",
       " '438',\n",
       " '439',\n",
       " '440',\n",
       " '441',\n",
       " '442',\n",
       " '443',\n",
       " '444',\n",
       " '445',\n",
       " '446',\n",
       " '447',\n",
       " '448',\n",
       " '449',\n",
       " '450',\n",
       " '451',\n",
       " '452',\n",
       " '453',\n",
       " '454',\n",
       " '455',\n",
       " '456',\n",
       " '457',\n",
       " '458',\n",
       " '459',\n",
       " '460',\n",
       " '461',\n",
       " '462',\n",
       " '463',\n",
       " '464',\n",
       " '465',\n",
       " '466',\n",
       " '467',\n",
       " '468',\n",
       " '469',\n",
       " '470',\n",
       " '471',\n",
       " '472',\n",
       " '473',\n",
       " '474',\n",
       " '475',\n",
       " '476',\n",
       " '477',\n",
       " '478',\n",
       " '479',\n",
       " '480',\n",
       " '481',\n",
       " '482',\n",
       " '483',\n",
       " '484',\n",
       " '485',\n",
       " '486',\n",
       " '487',\n",
       " '488',\n",
       " '489',\n",
       " '490',\n",
       " '491',\n",
       " '492',\n",
       " '493',\n",
       " '494',\n",
       " '495',\n",
       " '496',\n",
       " '497',\n",
       " '498']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [str(i) for i in range(264, len(vectorDocuments)+265)]\n",
    "vector_store.add_documents(documents=vectorDocuments, ids=ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Chat Completion Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "('* {\"소속\": \"중앙당\", \"이름\": \"황정아\", \"직책\": \"대변인\", \"슬로건\": \"\"} [{\\'국회\\': '\n",
      " \"'https://www.assembly.go.kr/members/22nd/HWANGJUNGA', '네이버블로그': \"\n",
      " \"'https://blog.naver.com/k0heaven', '유튜브': \"\n",
      " \"'https://www.youtube.com/@hwangjunga2024', '이미지': \"\n",
      " \"'https://theminjoo.kr/people/connect/people/1446/profile.jpg', '인스타그램': \"\n",
      " \"'https://www.instagram.com/junga1004/'}]\")\n",
      "('* {\"소속\": \"국회의원\", \"이름\": \"황정아\", \"직책\": \"국회의원(대전, 유성구을)\", \"슬로건\": \"\"} [{\\'국회\\': '\n",
      " \"'https://www.assembly.go.kr/members/22nd/HWANGJUNGA', '네이버블로그': \"\n",
      " \"'https://blog.naver.com/k0heaven', '유튜브': \"\n",
      " \"'https://www.youtube.com/@hwangjunga2024', '이미지': \"\n",
      " \"'https://theminjoo.kr/people/connect/people/1446/profile.jpg', '인스타그램': \"\n",
      " \"'https://www.instagram.com/junga1004/'}]\")\n",
      "('* {\"type\": \"서면브리핑\", \"title\": \"[황정아 대변인] 여론조사검증제도개선특위 발족, 건강한 공론장을 위한 과제들을 '\n",
      " '추진해 나가겠습니다\", \"content\": \"황정아 대변인 서면브리핑\\\\n■\\\\n여론조사검증제도개선특위 발족, 건강한 공론장을 위한 '\n",
      " '과제들을 추진해 나가겠습니다\\\\n\\\\n여론조사는 국민의 생각을 담아내는 중요한 공적 자원입니다. 정책과 정치의 방향을 결정하는 데 '\n",
      " '활용되며, 유권자가 올바른 판단을 내릴 수 있도록 돕는 민주사회의 필수 요소입니다.\\\\n그러나 최근 여론조사의 질문 문항, 응답률과 '\n",
      " '편향성에 관한 여러 의혹과 비판이 대두되며 공론장의 신뢰가 심각하게 훼손되고 있습니다.\\\\n‘명태균 게이트’를 통해 여론조사의 취약점들이 '\n",
      " '발견되고, 여론이 왜곡되어 민주주의 시스템 자체를 위협할 수 있음이 적나라하게 밝혀졌습니다.\\\\n더불어민주당은 이러한 위협에 맞서기 위해 '\n",
      " '여론조사검증제도개선특위를 발족합니다. 여론조사의 왜곡 혹은 조작이 이뤄질 수 없도록 검증하고, 국민께 알리겠습니다. 건강한 공론장을 '\n",
      " '조성하기 위한 제도 개선 과제도 적극 추진하겠습니다.\\\\n여론을 왜곡시키는 ‘제 2의 명태균 게이트’가 발생할 수 없도록 철저하게 감시해 '\n",
      " '나가겠습니다.\\\\n2025년 1월 20일\\\\n더불어민주당 공보국\", \"date\": \"2025-01-20\"} [{\\'url\\': '\n",
      " \"'https://theminjoo.kr/main/sub/news//view.php?sno=80&brd=11&post=1209007&search='}]\")\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(query=\"황정아\",k=3)\n",
    "print(len(results))\n",
    "for doc in results:\n",
    "    pprint(f\"* {doc.page_content} [{doc.metadata}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "after_rag_template = \"\"\"Refer to the content below and respond in Korean. Ensure that your response sounds natural, as if you are directly providing the answer yourself.:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "after_rag_prompt = ChatPromptTemplate.from_template(after_rag_template)\n",
    "after_rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | after_rag_prompt\n",
    "    | model_local\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "황정아 대변인은 최근 두 가지 중요한 이슈를 언급했습니다. 첫 번째는 여론조사검증제도의 개선입니다. 그녀는 최근 여론조사가 질문 문항, 응답률 및 편향성 측면에서 여러 논란이 제기되고 있다고 지적하며, 이를 해결하기 위해 여론조사검증제도를 개선할 것을 발표했습니다. 이는 국민의 신뢰를 회복시키고 정확한 공공 의견을 반영하는 데 중요하다고 강조했습니다.\n",
      "\n",
      "두 번째로 언급된 것은 설 명절 기간 동안 발생한 내란 문제와 그에 따른 경제 및 민생 회복입니다. 황정아는 이러한 상황이 경제와 국민의 생활에 큰 부담을 주고 있다며, 이를 조기 종식하고 민생 경제를 살리겠다는 명확한 입장을 밝혔습니다. 그녀는 내란 세력들이 헌법과 법치에 대해 어긋나는 행동을 하고 있다며 비판하면서, 국민의 요구를 충족시키기 위한 책임 있는 조치가 필요하다고 강조했습니다.\n",
      "\n",
      "이 두 가지 주제 모두 황정아 대변인은 정부와 시민사회에게 즉각적인 관심과 대응을 요구하며, 국가의 안정성과 국민의 복지를 최우선으로 여기고 있다는 입장을 분명히 했습니다.\n"
     ]
    }
   ],
   "source": [
    "print(after_rag_chain.invoke(\"황정아가 최근에 얘기한거?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
